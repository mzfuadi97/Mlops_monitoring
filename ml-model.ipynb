{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Machine Learning Pipeline - Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"churn-pipeline\"\n",
    "\n",
    "# Pipeline inputs\n",
    "DATA_ROOT = \"data\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "\n",
    "# Pipeline outputs\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\envs\\mlops-submission1\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\envs\\mlops-submission1\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_8/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_9/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_8/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_9/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Transform\\transform_graph\\6\\.temp_path\\tftransform_tmp\\6b676946b2624957bf4399af38ee43ea\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Transform\\transform_graph\\6\\.temp_path\\tftransform_tmp\\6b676946b2624957bf4399af38ee43ea\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Transform\\transform_graph\\6\\.temp_path\\tftransform_tmp\\c82c0ef9f65c410ea5b4939866002ece\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Transform\\transform_graph\\6\\.temp_path\\tftransform_tmp\\c82c0ef9f65c410ea5b4939866002ece\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " job_xf (InputLayer)            [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " marital_xf (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " education_xf (InputLayer)      [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " default_xf (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " housing_xf (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " loan_xf (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " contact_xf (InputLayer)        [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " month_xf (InputLayer)          [(None, 11)]         0           []                               \n",
      "                                                                                                  \n",
      " day_of_week_xf (InputLayer)    [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " poutcome_xf (InputLayer)       [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " duration_xf (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " campaign_xf (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " pdays_xf (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " previous_xf (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " emp.var.rate_xf (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " cons.price.idx_xf (InputLayer)  [(None, 1)]         0           []                               \n",
      "                                                                                                  \n",
      " cons.conf.idx_xf (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " euribor3m_xf (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " nr.employed_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 73)           0           ['job_xf[0][0]',                 \n",
      "                                                                  'marital_xf[0][0]',             \n",
      "                                                                  'education_xf[0][0]',           \n",
      "                                                                  'default_xf[0][0]',             \n",
      "                                                                  'housing_xf[0][0]',             \n",
      "                                                                  'loan_xf[0][0]',                \n",
      "                                                                  'contact_xf[0][0]',             \n",
      "                                                                  'month_xf[0][0]',               \n",
      "                                                                  'day_of_week_xf[0][0]',         \n",
      "                                                                  'poutcome_xf[0][0]',            \n",
      "                                                                  'age_xf[0][0]',                 \n",
      "                                                                  'duration_xf[0][0]',            \n",
      "                                                                  'campaign_xf[0][0]',            \n",
      "                                                                  'pdays_xf[0][0]',               \n",
      "                                                                  'previous_xf[0][0]',            \n",
      "                                                                  'emp.var.rate_xf[0][0]',        \n",
      "                                                                  'cons.price.idx_xf[0][0]',      \n",
      "                                                                  'cons.conf.idx_xf[0][0]',       \n",
      "                                                                  'euribor3m_xf[0][0]',           \n",
      "                                                                  'nr.employed_xf[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          18944       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           1040        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,449\n",
      "Trainable params: 36,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.2269 - binary_accuracy: 0.9071 - val_loss: 0.1952 - val_binary_accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1816 - binary_accuracy: 0.9164 - val_loss: 0.1910 - val_binary_accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1729 - binary_accuracy: 0.9197 - val_loss: 0.1957 - val_binary_accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1662 - binary_accuracy: 0.9223 - val_loss: 0.1924 - val_binary_accuracy: 0.9064\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1603 - binary_accuracy: 0.9247 - val_loss: 0.1976 - val_binary_accuracy: 0.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1549 - binary_accuracy: 0.9286 - val_loss: 0.2037 - val_binary_accuracy: 0.9059\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1486 - binary_accuracy: 0.9315 - val_loss: 0.2300 - val_binary_accuracy: 0.9067\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1433 - binary_accuracy: 0.9343 - val_loss: 0.2264 - val_binary_accuracy: 0.9078\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1338 - binary_accuracy: 0.9393 - val_loss: 0.2430 - val_binary_accuracy: 0.8967\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1273 - binary_accuracy: 0.9426 - val_loss: 0.2610 - val_binary_accuracy: 0.9026\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\churn-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029F0F2A1AC0> and <keras.engine.input_layer.InputLayer object at 0x0000029EC4B58520>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029F0F2A1AC0> and <keras.engine.input_layer.InputLayer object at 0x0000029EC4B58520>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029ECA23BBE0> and <keras.engine.input_layer.InputLayer object at 0x0000029ECA23BB20>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029ECA23BBE0> and <keras.engine.input_layer.InputLayer object at 0x0000029ECA23BB20>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029ECA05DC40> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFAD8700>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029ECA05DC40> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFAD8700>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC5304670> and <keras.engine.input_layer.InputLayer object at 0x0000029EDF7DA130>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC5304670> and <keras.engine.input_layer.InputLayer object at 0x0000029EDF7DA130>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC511AB50> and <keras.engine.input_layer.InputLayer object at 0x0000029F1111FF10>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC511AB50> and <keras.engine.input_layer.InputLayer object at 0x0000029F1111FF10>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC48D8A30> and <keras.engine.input_layer.InputLayer object at 0x0000029EC7B73670>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC48D8A30> and <keras.engine.input_layer.InputLayer object at 0x0000029EC7B73670>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC7C2C610> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFBDA5E0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029EC7C2C610> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFBDA5E0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029F0F364F10> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFBE5C70>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000029F0F364F10> and <keras.engine.input_layer.InputLayer object at 0x0000029EDFBE5C70>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\envs\\mlops-submission1\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\envs\\mlops-submission1\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    training_steps=1000,\n",
    "    eval_steps=800,\n",
    "    serving_model_dir=serving_model_dir\n",
    ")\n",
    "\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "BeamDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
